\section{Methods}

We propose a model of cognitive map formation driven by an agent’s experience within a closed environment.

The architecture operates with minimal external inputs—limited to binary reward and collision signals—as illustrated in Figure \ref{fig:model}\textbf{a}.
Instead of relying on exteroceptive cues, spatial representations emerge from idiothetic information, that is, the agent's internal perception of self-motion \cite{zhou2022}, consistent with the integration frameworks of the prior path.
In practice, we use the agent's ground truth velocity vector, \textit{ that is,} its actual displacement within the environment, as the primary navigational signal, reflecting the integration of inertial and proprioceptive signals observed in biological systems \cite{jerjian2023, whishaw1999}.
Since no visual information is used, the agent effectively navigates in the dark.

\paragraph{Place Cell Formation}

The primary spatial representation is formed by a set of simplified grid cell modules, each encoding a periodic tiling of 2D space, which directly maps to a toroidal manifold $\mathbf{T}^2$ (Fig. \ref{fig:model}\textbf{b}).
Departing from traditional grid cell modeling approaches \cite{dabaghian, schoyen2025}, we generate population activity directly via Gaussian tuning over a torus, continuously updated using the agent’s velocity vector—an approach used in prior work \cite{li2019}.

The grid cell population vector $\mathbf{u}^{\text{GC}}$ is forwarded to a place cell network with initial zero synaptic weights.
When no place cell is sufficiently active for a given input, a silent unit is randomly selected and imprinted with the current grid activity pattern.
To enforce sparsity in the place cell population vector and a clear spatial tuning specificity, a lateral inhibition mechanism is implemented by comparing the cosine similarity between the new weight vector $\mathbf{W}^{\text{GC},\text{PC}}_{i}$ and the existing nonzero weights $\textbf{W}^{\text{GC},\text{PC}}_{j\neq i}$ against a threshold $\theta^{\text{PC}}_{\text{inh}}$, if it is above then the new place cell is discarded.

The activation of each place cell is calculated through a bounded cosine similarity function, determining its corresponding place field (Fig. \ref{fig:model}\textbf{d}). Further implementation details, including lateral inhibition and recurrent connectivity, are provided in the appendix.


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\textwidth]{figures/figure_model_v2.png}
    \caption{\textbf{Model layout and spatial representations} -
    \textbf{a}: \textit{the full architecture of the model, consisting of three main sensory inputs, targeting the two modulators and the cognitive map module, and the executive components, represented by a policy module, two behavioral programs, and a reward receiver}.
    \textbf{b}: \textit{a module of grid cells defined in a bounded square space of length 1, and an activity representation of their receptive field over a torus}.
    \textbf{c}: \textit{the neural activity of a grid cell module from a random trajectory; in blue the repeating activity of all cells, while in green the activity of only one, highlighting the periodicity in space}.
    \textbf{d}: \textit{the distribution in space of the place cells centers, together with the activity of two cells showing the size of their place field}.
    \textbf{e}: \textit{neuromodulation activity over the place cells map, with in blue the cells tagged by the collision modulation, and in green the ones targeted by reward modulation.}
\textbf{f}: \textit{The place cells layer can be regarded as a graph with values assigned to each node according to the modulation strength; a path-finding algorithm can then be used to connect any two nodes, taking into account the node values}.
}
    \label{fig:model}
\end{figure}

\paragraph{Neuromodulation}
Neuromodulators deliver event signals: rewards, denoted DA (for dopamine), and boundary collisions, denoted BND.
In particular, the latter is an internal variable correlating and tracking the sensory experience of mechanical collisions.
In the brain, such functionality might be partially supported by serotonin (5-HT), which has been proposed influencing and being affected by sensory processing \cite{jacob2018, sizemore2020a}, encoding unexpected uncertainty \cite{matias2017}, modulating neural excitability and synaptic plasticity \cite{celada2013, avery2017, palacios-filardo2019}, also in hippocampus CA1 neurons \cite{kemp2005, teixeira2018}.

They are driven by binary inputs and defined through a leaky variable with exponential decay.


Each modulator $k$ updates its connection weights with the place cells through a Hebbian rule based on place cell activity $\mathbf{u}^{\text{PC}}$ and the error:

\begin{equation}
    \Delta \mathbf{W}^k = \eta^k \mathbf{u}^{\text{PC}} \left(v^k - \mathbf{W}^{k}\right)
\end{equation}

The term in brackets can be considered an error, implementing a simple form of predictive coding, and is inspired by temporal-difference learning \cite{sutton}, aligning with evidence that neuromodulatory systems signal prediction errors and update beliefs \cite{montague1996a, decothi2022, krishnan2022a}.
This plasticity mechanism provides resilience to environmental changes (e.g., moving rewards and new walls).

The weight vectors are restricted to remain non-negative.
Reward modulation tags cells near the rewarded locations, whereas boundary modulation builds a representation of the environmental edges. The result is a set of scalar fields over the place cells, and it forms the core of our model of a cognitive map (Fig.~\ref{fig:model}\textbf{e}).
See the appendix for full learning rules and parameter settings.

\paragraph{Modulation of Place Fields}
We further tested whether neuromodulators could directly alter spatial tuning. Place fields were dynamically shifted and resized based on recent salience signals.

Following a salient event (reward or collision), the place field centers were displaced in the grid cell space with the magnitude scaled by the neuromodulator $v^k$ and proximity to the event:

\begin{equation}
\Delta \mathbf{W}^{\text{GC}, \text{PC}}_i = c^{k} v^{k} \varphi_{\sigma^{k}}(\mathbf{u}^{\text{GC}} - \mathbf{W}^{\text{GC}, \text{PC}}_i)
\end{equation}

Here, $\varphi$ is a Gaussian function with width $\sigma^{k}$ and $c^{k}$ a scaling factor. This rule is inspired by BTSP plasticity \cite{bittner2017, milstein2021}, which shifts CA1 place fields following salient experiences.
This action was applied only to recently active cells, that is, with an activity trace greater than a threshold $\theta^{k}$.
Further, lateral inhibition prevents field overlap during remapping.

In addition to dislocation, the field size was modulated by scaling the gain of recently active neurons.
Such a mechanism allows neuromodulators to transiently enhance or suppress spatial sensitivity for specific cells.
This modulation rule involves the gain $\beta_i$ of each cell being adjusted proportionally to its activity trace $m_i$, a reference gain constant $\bar{\beta}$, and a modulatory scaling variable:
\begin{equation}
    \beta_{i} = c^{k}_{a} m_{i} \bar{\beta} + (1 - m_{i}) \bar{\beta}
\end{equation}

\noindent where $c^{k}_{a}$ is a scaling gain parameter, for which a value of 1 means that there is no modulation.


\paragraph{Policy and Behavior}
To evaluate the utility of the model in navigation, we implemented a simple policy that toggled between exploration and reward-seeking behavior, depending on an external reward trigger and the internal map.

Planning was defined as the action protocol of selecting a goal position; the calculation of a trajectory as a sequence of place cells starting with the one corresponding to the current position and ending with the nearest to the goal position; and the execution of actions to visit the entire sequence. For the trajectory, a graph-based pathfinding algorithm was used, in which place cells served as nodes, while synaptic connections acted as edges.
In addition, a cost function was introduced in the graph nodes, which assigns lower values to BND-modulated cells. This was designed to discourage proximity to the walls of the environment, as shown in plot \ref{fig:model}\textbf{f}.

Exploration consisted of two possible strategies: a random walk, for purely stochastic movements, and periodic goal-directed navigation towards a random but visited location, aimed at preventing stagnation.

In contrast, exploitation—defined as reward-directed navigation—involved identifying the reward location within the cognitive map.
This location corresponded to the average position of DA-modulated place cells, reflecting mechanisms such as hippocampal replay and value-based navigation \cite{mcnamara2014, michon2021, shamash2021}.


% benchmarks used
\paragraph{Naturalistic task}
The model was evaluated on a biologically inspired navigation benchmark involving exploration and goal-seeking behavior in closed environments. Performance was measured as the total number of rewards collected in multiple trials.

Optimization of the model hyperparameters was carried out using the evolutionary Covariance-Matrix Adaptation Strategy (CMA-ES) \cite{igel2007}.
The choice of hyperparameters to evolve took into account the type of dynamics for which it was difficult to select predefined values; the number of evolved variables was 10.
The use of such method derived from the impracticality of other optimization algorithms, also given the non-differentiability of several dynamic.
Viable alternatives were based on reinforcement learning, Bayesian, and grid search, but evolution was more appealing for exploration and visualization of the parameter space exploration.
For evaluating the individuals, it was used a multi-objective fitness function: maximization of the reward count, and minimization of the collision count from the time the reward position was discovered.


