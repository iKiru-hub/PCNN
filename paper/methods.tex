\section{Methods}

The model is constructed around the concept of a cognitive map, which an agent builds by freely navigating a closed environment and reaching a discovered goal location. The full schema of its components its illustrated in plot \ref{fig:model}-\textbf{a} below.
The architecture relies on the core assumption that the agent has receives minimal external information, consisting solely of a reward and collision input as two binary values.
These two signals are used to enrich the cognitive map with experience-dependent data, which is then used to guide the agent's behavior.
% briefly describe where in the brain these signals are processed

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/figure_model.png}
    \caption{\textsc{Model layout and spatial representations} - \textbf{a}: \textit{the full architecture of the model, consisting of three main sensory input, targeting the two modulators and the cognitive map module, and the executive components, represented by a policy module, two behavioural programs
    and a reward receiver}. \textbf{b}: \textit{the cognitive map component, organized with a stack of grid cell modules receiving the velocity input and projecting to two layer of place cells with different place field granularity}. \textbf{c}: \textit{the neural activity of a grid cell module from
a random trajectory; in blue the repeating activity of all cell, while in green the activity of only one, highlighting the periodicity in space}. \textbf{d}: \textit{the distribution in space of the place cells centers, together with the activity of two cells showing the size of their place field}.
\textbf{e}: \textit{neuromodulation activity over the place cells map, with in blue the cells tagged by the collision modulation, and in green the ones targeted by reward modulation.}}
    \label{fig:model}
\end{figure}

The formation of the spatial representation is instead based on idiothetic information, which is the agent's perception of self-motion \cite{zhouCorticalMechanismsMultisensory2022}.
In particular, here we assume this cue to be the factual velocity vector, namely the actual displacement of the agent in the environment.
In the brain, this signal is thought to result from the integration of inertial and relative motion cues \cite{jerjianSelfmotionPerceptionSequential2023, whishawCalibratingSpaceExploration1999a}.

\subsection{Place cell map}
The formation of place cells is obtained from the activity of a set of grid cells organized into modules, or layers. This simple feed-forward architecture is depicted in plot \ref{fig:model}-\textbf{b}.
A grid cell module $i$ has been defined as a set of $N^{\text{gc}}$ neurons with gaussian tuning curve evenly distributed over the surface of a two dimensional torus $\mathbf{T}^{2}$.
Unlike other approaches for generating grid fields \cite{dabaghianGridCellsBorder, schoyenHexagonsAllWay2025}, we defined a correspondance between the global environment in which the agent moves, a two dimensional Euclidean space $\mathbf{R}^{2}$, and a grid module bounded local space, corresponding to the torus.
Then, the global velocity $\mathbf{v}=\{x,y\}$ is then mapped to a local velocity, scaled by a speed scalar $s^{\text{gc}}_{i}$ specific to the grid cell module $i$, which determines its periodicity in space. This approach has been used in previous works \cite{liModelingPlaceCells2019}.
The initial position on the torus is randomly chosen at the beginning of each episode, since what matters is the sequence of displacements without any reference to a meaningful origin.

The choice of a toroidal space is motivated by consolidated experimental evidence of the neural space of grid cells, which are organized in modules of different size spanning the animal's environment. However, the shape of their firing pattern is known to be hexagonal, which corresponds to the optimal tiling of a two dimensional plane, giving rise to a neural space lying on a twisted torus.
In this work, for simplicity, we consider a square tiling and thus a square torus, without much loss of generality except for the slight increase of grid cells required for a sufficiently cover.
In plot \ref{fig:model}-\textbf{c} is shown the activity of a grid cell module over a trajectory, with the periodicity underlined by the cell in green.

The activity of all grid cell modules, indicated as $\textbf{u}^{\text{GC}}$, is then projected down to two independent layers of initially un-tuned cells, whose feed-forward weights $\textbf{W}^{\text{GC},\text{PC1}}$; $\textbf{W}^{\text{GC},\text{PC2}}$ are initialized at zero.
As the agent moves and the grid cells activity changes, if no neurons within a place cell layer are active, then one is randomly chosen and its weights are set to the current (at time $t$) grid cells' population vector $\textbf{W}^{\text{GC},\text{PC}}_{i}\leftarrow \textbf{u}^{\text{GC}}_{t}$.
For the plasticity process to be completed, it is also checked the possible overlap with other cells in the same layer, effectively accounting for lateral inhibition. This mechanism is implemented by computing the cosine similarity with the weight vector of the other tuned cells and comparing it with a threshold $\theta^{\text{PC}}_{\text{rep}}$, with the possibility of aborting the plasticity process if the similarity is too high.

The activity of a tuned place cell $i$ is given, again, by the cosine similarity between the current grid cells' population vector and the weight vector of the cell:
\begin{equation}
    \textbf{u}^{\text{PC}}_{i}=\phi\left(\cos\left(\textbf{u}^{\text{GC}},\textbf{W}^{\text{GC},\text{PC}}_{i}\right)\right)
\end{equation}
\noindent where $\phi$ is a generalized sigmoid function $\phi(z)=\left[1 + \exp(-\beta(z-\alpha))\right]^{-1}$ with gain $\beta$ and threshold $\alpha$.
The two layers of place cells differ in the size of their place fields. This feature is affected by the sensitivity of a cell tuning with respect to the grid cell activation, determined by the parameters of the sigmoid, and the strength of the lateral inhibition, determined by the similarity threshold.
Within a layer, the connections between cells are calculated by the same cosine similariy, but compared against a different threshold $\theta^{\text{PC}}_{\text{rec}}$.
One layer is set to be more fine-grained, with an overall higher density of place cells over the space, while the other is more coarse-grained, with overall large place field sizes.

In figure \ref{fig:model}-\textbf{d} are shown the centers of one of the fine-grained layer and the activity of two cells, with their place field highlighted as an heatmap.


\subsection{Neuromodulators}
The fine-grained layer of place cells constitutes the main cognitive map of the agent, since it captures the environment with greater detail.
The neuromodulators are operationalized as analog sensors of meaningful environmental events, here reward and collision, and map directly to the place cells through plastic connections $W^{k,\text{PC}}$.
For each neuromodulator $k$, it is defined a leaky variable $v^{k}$ that accumulates the corresponding signal $I$ over time, and decays exponentially to zero in the absence of inputs with time constant $\tau^{k}$:
\begin{equation}
    \dot{v}^{k}=-v^{k} / \tau^{k} + I
\end{equation}

\noindent This variable is then paired with the activity of each place cell $i$ for updating the synaptic weights in a Hebbian fashion:
\begin{equation}
    \Delta \textbf{W}^{k}_{i}=\eta^{k} v^{k} \textbf{u}^{\text{PC}}_{i}
\end{equation}

\noindent where $\eta^{k}$ is the neuromodulator-specific learning rate.

On the one hand, the reward modulation, signed as $\textbf{W}^{\text{DA}}$, is sensitive to the instantaneous presence of reward, defined as a boolean value. Over time, its coupling with the population vector $\textbf{u}^{PC}_{t}$ delineates a region of the environment where the reward has been experienced.
On the other hand, the collision modulation, referred to as $\textbf{W}^{\text{BND}}$, signals the occurrence of a collision with a boundary, which is again given as a boolean. After enough events, the profile of the resulting weight matrix with the place cells provides an approximation of the shape of the environment given by its boundaries. From the perspective of the agent, this intuition of the topology of its surroundings is crucial for effectively planning routes to target locations.


At each moment during navigation, the weight matrices $\textbf{W}^{\text{DA},\text{PC}},\;\textbf{W}^{\text{BND},\text{PC}}$ act as scalar fields over the neural space of the place cells, and their simultaneous contributions delineate what in this work is referred to as a cognitive map.
In plot \ref{fig:model}-\textbf{e} is shown the activity of the two neuromodulators over the fine-grained place cells map, showcasing the bounds of the environment and the reward location.


\subsection{Policy and behavior}
In this work, the first interest was to test the usefulness of our simple cognitive map built from minimal assumptions for the tasks of exploration and goal-directed navigation.
To this end, we defined a simple hard-coded policy that toggles between these two behaviours according to the presence of a goal signal, externally provided, and the presence of an actual goal representation, taken care of by a special component called \textit{reward seeking}, depicted in the pink box of plot \ref{fig:model}-\textbf{a}.
Exploration is accomplished by a random walk, with a variable number of steps in the same direction to avoid stagnation, and occasional plans to visit random positions within the known map, again for limiting stagnation.
Goal-directed navigation, either for reaching a random position for exploration or the actual reward location, is achieved by calculating the shortest path between the closest place cells centers of the current and target positions. The place cells are hence treated as nodes of a graph, and their connections constitute its edges.
We use a Dijkstra algorithm applied to the coarse-grained layer, which contains less and more spread out cells and it is thus cheaper to compute, to derive a coarse-grained plan.
However, in the case the agent gets stuck or the distance to the target is shorter than the cells' distance, the planning switches to the other layer for devising a fine-grained plan, which it is followed until either the target or the next node in the coarse-grained are reached.

The advantage of this dual-layer planning lies in its flexibility, as it lightens the computational load of planning by exploing the sparser and lighter map and only invokes the detailed one when necessary.
In the process of behaviour, learning does not occur explicitly, but it is instead accounted for in the online formation of the cognitive map.


\subsection{Map re-configuration}
Our second aim was to investigate the possibility of online alteration of the place cells density, in terms of its potential performance improvement.
This action is motivated by the consolidated phenomenon of hippocampal rate remapping, for which the place cells change their firing pattern according to contextual shifts \cite{andersonHeterogeneousModulationPlace2003, fentonRemappingRevisitedHow2024}. Additionally, there is growing experimental evidence that place fields can be moved in space following
behaviourally relevant events, such as the occurrence of reward, according to a plasticity rule known as behavioural time-scale plasticity (BTSP) \cite{bittnerBehavioralTimeScale2017, miikkulainenEvolvingDeepNeural2017}.

In our model, we associated this process to both collision and reward signals, whose location is set to be the center towards which the cells within a certain radius $r_{\text{BND}},\;r_{\text{DA}}$ are pulled. The centers of the cells involved are shifted with a force proportional to the Gaussian distance from the center of the signal, and the strength is weighted by a parameter $\lambda_{\text{BND}},\;\lambda_{\text{DA}}$.

Our working hypothesis is that the online re-configuration of the cognitive map can lead to a representation of the environment more tailored with the agent experience. This changes introduced by this mechanism should then be reflected in the adaptability and navigation abilities.



















