
\section{Discussion}
Exploration and planning in novel and past environments are essential behaviors of animals, directly affecting their success in spatial understanding and goal reaching.

% brief recap
An important element behind these abilities is the formation of a map of their surroundings, enriched with information gained from new experiences, known as a cognitive map.
In this work, we presented a rate network model inspired by the CA1 hippocampal region \cite{donato2023}, which differs from previous approaches as it operates online, uses neuromodulation-based plasticity and does not rely on external coordinates.

We used simplified grid cells together with synaptic plasticity as a mechanism to develop information-rich representations based on place cells updated through experience, grouped with common perspectives on cognitive maps \cite{hok2007}.
In the spirit of minimizing the geometric assumptions in the neural space, we treated the generated place network as a topological graph.
More specifically, its formation only involved velocity inputs, reminiscent of path-integration, and with sensory information added locally through the action of neuromodulators.
This idea aligned with the concept of a \textit{labeled graph} \cite{ishikawa2006, warren2019}, however, it is also true that no metric violations were possible in these settings.
The employment of the cognitive maps for goal-directed planning occurred through a path-planning algorithm treating the place cells network as a graph of nodes, and meant to be a neural-based variant of the Dijkstra algorithm \cite{javaid2013}, a popular choice for graph computations.
Indeed, our algorithm relied on biologically plausible neural operations, such activity propagation through the network and utilization of synaptic activity traces as masks for identifying the best neighboring place cells.

The tasks we applied the agent to consisted of an exploratory and exploitative phase, in which the system was tasked to plan and reach reward positions.
For simplicity, the first stage relied on a random walk process, as it was outside the scope of this work.
This choice had the side effect that the reward was not always discovered, leading to the formation of incomplete maps, and thus impairing performance. However, this issue had limited consequences.

% DRAWBACKS and LIMITATIONS of your model. is the Dijstra algo biological plausible, other aspects of your model or assumptions that could be improved

% I
The simulation results validated the model, showing the expected emergence of cognitive maps and their encoding of information collected during the experience.
The online formation of the locations on the map aligns with the idea of using only idiothetic velocity input, as in path integration \cite{gallistel1996, gillner1998, mcnaughton2006}.
Previous work followed a similar direction using recurrent networks, but required extensive gradient-based training \cite{sorscher2023, cueva2018, whishaw1999}.
Another important difference is that our resulting neural network was composed solely of place cells, although neuromodulated, and no other types of neurons were present.
This distinction is justified by the partially different task structure, which did not involve supervised learning and did not receive visual information as in \cite{banino2018}.
Furthermore, our model relied on predefined grid cell layers, which constituted a strong and sufficient inductive bias, and did not have to be learned from scratch.

An additional relevant aspect is also the consideration of the place cell layer as an explicit graph data structure, on which the path-planning algorithm was applied. The plausibility of the algorithm lies in the usage of the connectivity matrix and activity-dependent variables, not necessitating information external to the model. It is directly inspired by the Dijkstra algorithm. 

The adoption of this level of description leads to robustness and flexibility, enabling effective navigation in all tested environments, which varied in layout complexity.
Nevertheless, this approach did act as another clear inductive bias, which lifted the need to learn an approximation of it through network dynamics and even more differently tuned neurons.


% II
Adaptability was tested by occasionally moving the reward position, leading to the generation of an internal prediction error that was used to update its representation on the map.
The agent was proved capable of unlearning previous associations, returning to exploration, and memorizing new reward locations.
This behavioral protocol is similar to previous work \cite{brzosko2017}, in which dopaminergic and cholinergic activity was utilized within a Hebbian plasticity rule to strengthen or weaken reward-associated spatial representations.
However, alternatively to exploiting neuromodulators with opposite valence, we followed the direction of temporal-difference learning and predictive coding, a direction linked to hippocampal representations \cite{decothi2022, aitken2022} and explored various computational approaches
\cite{halvagal2023, ororbia2023, stachenfeld2017}.
This choice departed from our focus on using the data encoded in the cognitive map itself, in which each position has an associated neuromodulation value array, encapsulated in the modulator connection weights, that functions as expected sensory experience to compare with the actual sensory experience and obtain a learning signal.
In fact, neuromodulation has long been associated with prediction errors \cite{fiorillo2003, sosa2021}, especially dopamine \cite{kempadoo2016, schultz2016, cools2019, sheynikhovich2023}.

A limitation of our model is the reduction of neuromodulation to external event sensors that define a two-dimensional input of sensory data.
Moreover, its actions are solely confined to value representation and alteration of place fields, which constitute a subset of the functionalities of brain neurmodulators. 


% III
Lastly, the relevance of active modulation of the neuronal properties of place cells was confirmed through simulated ablation experiments.
The primary finding was the statistically significant role of active boundary modulation, obtained by comparison with a model variant with neuromodulation disabled. This supports the importance of having a flexible representation of the environment layout.

Further investigation involved testing the effect of density and gain modulation separately.
The results reported a significant impact of altering the density of place cells on the total count of collected rewards.
In general, these results are consistent with the experimental observations of alteration of place cells following reward events \cite{bittner2017, nair2022}, in particular in terms of increased clustering of cells \cite{tryon2017, wirtshafter2020}, reminiscent of changes in firing rate after contextual changes \cite{anderson2003, lee2006}.
This relocation mechanism was stronger for the boundary cells, with the trend of pushing the place cell centers closer to the boundaries, and it proved to be statistically significant in improving performance.
For reward cells, the effect was weaker and did not improve behavior.

Concerning the modulation of place fields, there is significant experimental evidence of their alternation during reward events \cite{fyhn2002, lenck-santini2005, dupret2010}, some reporting shrinkage near reward objects \cite{burke2011}, and more markedly near boundaries \cite{tanni2022}. 

In our setup, place-field modulation was implemented by scaling the neural activation gain. This led to a general reduction in field size across all modulated cells.
In the case of boundary cells, this shrinking effect may account for the improved performance in two ways: first, by increasing the spatial resolution of the environment layout \cite{scleidorovich2022}; and second, by freeing up space for other place cells to form near.
The latter may result from reduced lateral inhibition and the inward shift of the field center toward the boundaries.
However, gain modulation alone did not produce statistically significant effects, indicating that it must be coupled with density modulation to produce measurable improvements.

For reward place cells, the impact of gain modulation was less pronounced. This may be due to the simplicity of the experimental protocol or reward signal, with the latter being defined purely in spatial terms and lacked any meaningful non-spatial feature.

Previous studies have proposed that Locus Coeruleus (LC) is involved in place cell overrepresentation near rewarding locations through the co-release of dopamine and noradrenaline \cite{kaufman2020}.
A possible experimental prediction that emerges from our results is that preventing place cell density modulation may indirectly decrease the quality of reward-directed navigation.
More specifically, this can be tested in animal models by pharmacological blocking of LC afferent CA1 connections, once reward has been experienced.
Then, the performance can be evaluated by considering: the count of rewards fetched; the difference between the animal's trajectory between the initial and reward location and the theoretical spatial geodesic (shortest path); and the average distance from the walls.
However, a relevant confounding variable in this set-up is the difficulty of isolate CA1 inputs, and the involvement of multiple and complex additional signals in the generation of the cognitive map.


% conclusion
In conclusion, this work showed a possible architecture for coupling emergent spatial representations with neuromodulated plasticity to achieve an experience-driven cognitive map.
The reliance on some spatial and algorithmic inductive biases, grid cells, and a planning algorithm supports the idea of a label graph for goal navigation.
Future work can investigate the application to other spatial domains, such as motor control and three-dimensional navigation.
In addition, a richer input feature can be added, such as visual information \cite{wen2024}, as well as new neuromodulators that encode different sensory dimensions or internally generated signals. 

